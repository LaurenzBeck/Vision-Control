{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.6-tf\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras.layers import Dense,GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "print(tf.keras.__version__)\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurenz\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "# Input constants\n",
    "HEIGHT = 65\n",
    "WIDTH = 62\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 60\n",
    "NUM_TRAIN_IMAGES = 660\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', \n",
    "                      include_top=False, \n",
    "                      input_shape=(HEIGHT, WIDTH, CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 660 images belonging to 60 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Generator constants\n",
    "TRAIN_DIR = \"simple_clock/Datagenerator_simple_clock/Training\"\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_datagen =  ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                    #rotation_range=0,\n",
    "                                    #horizontal_flip=False,\n",
    "                                    #vertical_flip=False,\n",
    "                                    width_shift_range=0.03,\n",
    "                                    height_shift_range=0.03,\n",
    "                                    #shear_range=0.0,\n",
    "                                    #zoom_range=0,\n",
    "                                    )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                    target_size=(HEIGHT, WIDTH),\n",
    "                                                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        # New FC layer, random init\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    # New softmax layer\n",
    "    predictions = Dense(num_classes, activation='sigmoid')(x) \n",
    "    \n",
    "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 65, 62, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 71, 68, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 33, 31, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 33, 31, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 33, 31, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 35, 33, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 17, 16, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 17, 16, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 17, 16, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 17, 16, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 17, 16, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 17, 16, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 17, 16, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 17, 16, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 17, 16, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 17, 16, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 17, 16, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 17, 16, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 17, 16, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 17, 16, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 17, 16, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 17, 16, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 17, 16, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 17, 16, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 17, 16, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 17, 16, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 17, 16, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17, 16, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 17, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 17, 16, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 17, 16, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 17, 16, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 17, 16, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 17, 16, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 17, 16, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 17, 16, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 17, 16, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17, 16, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 17, 16, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 9, 8, 128)    32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 9, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 9, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 9, 8, 128)    147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 9, 8, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 9, 8, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 9, 8, 512)    66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 9, 8, 512)    131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 9, 8, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 9, 8, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 9, 8, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 9, 8, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 9, 8, 128)    65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 9, 8, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 9, 8, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 9, 8, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 9, 8, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 9, 8, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 9, 8, 512)    66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 9, 8, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 9, 8, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 9, 8, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 9, 8, 128)    65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 9, 8, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 9, 8, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 9, 8, 128)    147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 9, 8, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 9, 8, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 9, 8, 512)    66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 9, 8, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 9, 8, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 9, 8, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 9, 8, 128)    65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 9, 8, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 9, 8, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 9, 8, 128)    147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 9, 8, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 9, 8, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 9, 8, 512)    66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 9, 8, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 9, 8, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 9, 8, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 5, 4, 256)    131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 5, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 5, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 5, 4, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 5, 4, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 5, 4, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 5, 4, 1024)   263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 5, 4, 1024)   525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 5, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 5, 4, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 5, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 5, 4, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 5, 4, 256)    262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 5, 4, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5, 4, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 5, 4, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 5, 4, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 5, 4, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 5, 4, 1024)   263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 5, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 5, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 5, 4, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 5, 4, 256)    262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 5, 4, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 5, 4, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 5, 4, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 5, 4, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 5, 4, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 5, 4, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 5, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 5, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 5, 4, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 5, 4, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 5, 4, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 5, 4, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 5, 4, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 5, 4, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 5, 4, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 5, 4, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 5, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 5, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5, 4, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 5, 4, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 5, 4, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 5, 4, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 5, 4, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 5, 4, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 5, 4, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 5, 4, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 5, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 5, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5, 4, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 5, 4, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 5, 4, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 5, 4, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 5, 4, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 5, 4, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 5, 4, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 5, 4, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 5, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 5, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 5, 4, 1024)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 3, 2, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 3, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 3, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 3, 2, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 3, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 3, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 3, 2, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 3, 2, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 3, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 3, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 3, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 3, 2, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 3, 2, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 3, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 3, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 3, 2, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 3, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 3, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 3, 2, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 3, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 3, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 3, 2, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 3, 2, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 3, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 3, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 3, 2, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 3, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 3, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 3, 2, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 3, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 3, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 3, 2, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12288)        0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          1228900     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          10100       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          10100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 60)           6060        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,852,972\n",
      "Trainable params: 1,265,260\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Top Layer constants\n",
    "FC_LAYERS = [100, 100, 100, 100]\n",
    "DROPOUT = 0.05\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=DROPOUT, \n",
    "                                      fc_layers=FC_LAYERS, \n",
    "                                      num_classes=NUM_CLASSES)\n",
    "\n",
    "finetune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 60 classes.\n",
      "Img1 - real: 0, pred: 330\n",
      "Img2 - real: 6, pred: 330\n",
      "Img3 - real: 12, pred: 312\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing the model\n",
    "TEST_DIR = \"simple_clock/Datagenerator_simple_clock/Testing\"\n",
    "\n",
    "IMG_PATH_1 = \"simple_clock/Datagenerator_simple_clock/Testing/0/clock-01.00.00.PNG\"\n",
    "IMG_PATH_2 = \"simple_clock/Datagenerator_simple_clock/Testing/6/clock-04.01.00.PNG\"\n",
    "IMG_PATH_3 = \"simple_clock/Datagenerator_simple_clock/Testing/12/clock-07.02.00.PNG\"\n",
    "\n",
    "test_datagen =  ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                 target_size=(HEIGHT, WIDTH),\n",
    "                                                 batch_size=1,\n",
    "                                                 class_mode=None,  # only data, no labels\n",
    "                                                 shuffle=False\n",
    "                                                )  \n",
    "\n",
    "preds = finetune_model.predict_generator(test_generator, 60)\n",
    "\n",
    "#visualizing some examples\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1, 3, 1)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_1), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Img1') \n",
    "a = fig.add_subplot(1, 3, 2)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_1), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Img2') \n",
    "a = fig.add_subplot(1, 3, 3)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_1), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Img3') \n",
    "print(\"Img1 - real: 0, pred: %d\" % (np.argmax(preds[0], axis=0)*6))\n",
    "print(\"Img2 - real: 6, pred: %d\" % (np.argmax(preds[1], axis=0)*6))\n",
    "print(\"Img3 - real: 12, pred: %d\" % (np.argmax(preds[2], axis=0)*6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "82/82 [==============================] - 43s 521ms/step - loss: 4.1178 - acc: 0.0229\n",
      "Epoch 2/125\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 4.0867 - acc: 0.0168\n",
      "Epoch 3/125\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 4.0549 - acc: 0.0290\n",
      "Epoch 4/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 4.0003 - acc: 0.0350\n",
      "Epoch 5/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.9497 - acc: 0.0335\n",
      "Epoch 6/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.8531 - acc: 0.0534\n",
      "Epoch 7/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.7508 - acc: 0.0671\n",
      "Epoch 8/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.6365 - acc: 0.0640\n",
      "Epoch 9/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.4959 - acc: 0.0717\n",
      "Epoch 10/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.3398 - acc: 0.0884\n",
      "Epoch 11/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.2325 - acc: 0.0762\n",
      "Epoch 12/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.1274 - acc: 0.1006\n",
      "Epoch 13/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.9814 - acc: 0.1143\n",
      "Epoch 14/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.9742 - acc: 0.1356\n",
      "Epoch 15/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.8682 - acc: 0.1494\n",
      "Epoch 16/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.7552 - acc: 0.1387\n",
      "Epoch 17/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.6801 - acc: 0.1570\n",
      "Epoch 18/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.6246 - acc: 0.1662\n",
      "Epoch 19/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.6009 - acc: 0.1723\n",
      "Epoch 20/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.5113 - acc: 0.2119\n",
      "Epoch 21/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.4754 - acc: 0.1951\n",
      "Epoch 22/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.4155 - acc: 0.2165\n",
      "Epoch 23/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.3245 - acc: 0.2332\n",
      "Epoch 24/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.3396 - acc: 0.2134\n",
      "Epoch 25/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.3361 - acc: 0.2287\n",
      "Epoch 26/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.2536 - acc: 0.2500\n",
      "Epoch 27/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.2182 - acc: 0.2622\n",
      "Epoch 28/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.1454 - acc: 0.2775\n",
      "Epoch 29/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.1887 - acc: 0.2409\n",
      "Epoch 30/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.0768 - acc: 0.2332\n",
      "Epoch 31/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.1641 - acc: 0.2165\n",
      "Epoch 32/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.0848 - acc: 0.2637\n",
      "Epoch 33/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.0520 - acc: 0.2896\n",
      "Epoch 34/125\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 2.0680 - acc: 0.2470\n",
      "Epoch 35/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.0458 - acc: 0.2561\n",
      "Epoch 36/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.0157 - acc: 0.2927\n",
      "Epoch 37/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.9832 - acc: 0.2927\n",
      "Epoch 38/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.9954 - acc: 0.2729\n",
      "Epoch 39/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.9673 - acc: 0.2851\n",
      "Epoch 40/125\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.9491 - acc: 0.2576\n",
      "Epoch 41/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.9375 - acc: 0.3094\n",
      "Epoch 42/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.8563 - acc: 0.3186\n",
      "Epoch 43/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.8949 - acc: 0.3308\n",
      "Epoch 44/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.8219 - acc: 0.3293\n",
      "Epoch 45/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.9109 - acc: 0.2851\n",
      "Epoch 46/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7656 - acc: 0.3400\n",
      "Epoch 47/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7480 - acc: 0.3643\n",
      "Epoch 48/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7788 - acc: 0.3399\n",
      "Epoch 49/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.8098 - acc: 0.3003\n",
      "Epoch 50/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.8071 - acc: 0.3430\n",
      "Epoch 51/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7256 - acc: 0.3567\n",
      "Epoch 52/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7910 - acc: 0.3414\n",
      "Epoch 53/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7704 - acc: 0.3216\n",
      "Epoch 54/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7167 - acc: 0.3659\n",
      "Epoch 55/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7485 - acc: 0.3613\n",
      "Epoch 56/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.7141 - acc: 0.3537\n",
      "Epoch 57/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6958 - acc: 0.3735\n",
      "Epoch 58/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6570 - acc: 0.3796\n",
      "Epoch 59/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6899 - acc: 0.3353\n",
      "Epoch 60/125\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.6090 - acc: 0.3994\n",
      "Epoch 61/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6053 - acc: 0.3704\n",
      "Epoch 62/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6397 - acc: 0.3689\n",
      "Epoch 63/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6086 - acc: 0.3781\n",
      "Epoch 64/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6429 - acc: 0.3780\n",
      "Epoch 65/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6235 - acc: 0.3506\n",
      "Epoch 66/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5734 - acc: 0.3857\n",
      "Epoch 67/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6291 - acc: 0.3674\n",
      "Epoch 68/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5619 - acc: 0.3659\n",
      "Epoch 69/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6356 - acc: 0.3902\n",
      "Epoch 70/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4838 - acc: 0.4497\n",
      "Epoch 71/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5575 - acc: 0.3979\n",
      "Epoch 72/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5160 - acc: 0.3994\n",
      "Epoch 73/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5304 - acc: 0.4101\n",
      "Epoch 74/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5056 - acc: 0.4009\n",
      "Epoch 75/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5821 - acc: 0.4009\n",
      "Epoch 76/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4140 - acc: 0.4451\n",
      "Epoch 77/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4500 - acc: 0.4466\n",
      "Epoch 78/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4566 - acc: 0.4299\n",
      "Epoch 79/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.5121 - acc: 0.4207\n",
      "Epoch 80/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4535 - acc: 0.4177\n",
      "Epoch 81/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4565 - acc: 0.4512\n",
      "Epoch 82/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4273 - acc: 0.4725\n",
      "Epoch 83/125\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.4516 - acc: 0.4177\n",
      "Epoch 84/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4433 - acc: 0.4238\n",
      "Epoch 85/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4185 - acc: 0.4574\n",
      "Epoch 86/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4064 - acc: 0.4238\n",
      "Epoch 87/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4054 - acc: 0.4604\n",
      "Epoch 88/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3744 - acc: 0.4314\n",
      "Epoch 89/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3821 - acc: 0.4314\n",
      "Epoch 90/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4211 - acc: 0.4466\n",
      "Epoch 91/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4065 - acc: 0.4451\n",
      "Epoch 92/125\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.3912 - acc: 0.4634\n",
      "Epoch 93/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3547 - acc: 0.4756\n",
      "Epoch 94/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4201 - acc: 0.4253\n",
      "Epoch 95/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3674 - acc: 0.4802\n",
      "Epoch 96/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3995 - acc: 0.4650\n",
      "Epoch 97/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4091 - acc: 0.4466\n",
      "Epoch 98/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3716 - acc: 0.4269\n",
      "Epoch 99/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3261 - acc: 0.4436\n",
      "Epoch 100/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3868 - acc: 0.4360\n",
      "Epoch 101/125\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.3526 - acc: 0.4466\n",
      "Epoch 102/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3481 - acc: 0.4695\n",
      "Epoch 103/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3303 - acc: 0.4970\n",
      "Epoch 104/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3584 - acc: 0.4482\n",
      "Epoch 105/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3019 - acc: 0.5015\n",
      "Epoch 106/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3155 - acc: 0.4710\n",
      "Epoch 107/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3325 - acc: 0.4589\n",
      "Epoch 108/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3254 - acc: 0.4512\n",
      "Epoch 109/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2356 - acc: 0.4954\n",
      "Epoch 110/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3174 - acc: 0.4695\n",
      "Epoch 111/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3358 - acc: 0.4665\n",
      "Epoch 112/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2138 - acc: 0.4985\n",
      "Epoch 113/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3387 - acc: 0.4787\n",
      "Epoch 114/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2859 - acc: 0.4954\n",
      "Epoch 115/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2856 - acc: 0.4924\n",
      "Epoch 116/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2502 - acc: 0.5320\n",
      "Epoch 117/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2662 - acc: 0.4893\n",
      "Epoch 118/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2865 - acc: 0.5061\n",
      "Epoch 119/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2522 - acc: 0.5046\n",
      "Epoch 120/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2104 - acc: 0.4985\n",
      "Epoch 121/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2668 - acc: 0.4909\n",
      "Epoch 122/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2910 - acc: 0.4772\n",
      "Epoch 123/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2893 - acc: 0.4741\n",
      "Epoch 124/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2444 - acc: 0.5213\n",
      "Epoch 125/125\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.1958 - acc: 0.5244\n"
     ]
    }
   ],
   "source": [
    "# Training constants\n",
    "NUM_EPOCHS = 125\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "###optional - loading weights\n",
    "#finetune_model.load_weights('checkpoints/ResNet50_model_weights.h5')\n",
    "\n",
    "filepath=\"./checkpoints/\" + \"ResNet50\" + \"_model_weights.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor=[\"acc\"],\n",
    "                             verbose=1,\n",
    "                             mode='max'\n",
    "                            )\n",
    "#early_stopping = EarlyStopping(monitor='acc', min_delta=0.002, patience=4, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "adam = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "finetune_model.compile(adam,\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "history = finetune_model.fit_generator(train_generator, \n",
    "                                       epochs=NUM_EPOCHS,\n",
    "                                       workers=8, \n",
    "                                       steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE, \n",
    "                                       shuffle=True,\n",
    "                                       #callbacks=callbacks_list\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting constants\n",
    "PLOT_PATH = 'acc_vs_epochs_resnet50.png'\n",
    "\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r.')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.savefig(PLOT_PATH)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img1 - real: 0, pred: 318\n",
      "Img2 - real: 6, pred: 318\n",
      "Img3 - real: 12, pred: 318\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing the model again\n",
    "preds = finetune_model.predict_generator(test_generator, 60)\n",
    "\n",
    "#visualizing some examples\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1, 3, 1)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_1), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Img1') \n",
    "a = fig.add_subplot(1, 3, 2)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_1), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Img2') \n",
    "a = fig.add_subplot(1, 3, 3)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_1), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Img3') \n",
    "print(\"Img1 - real: 0, pred: %d\" % (np.argmax(preds[0], axis=0)*6))\n",
    "print(\"Img2 - real: 6, pred: %d\" % (np.argmax(preds[1], axis=0)*6))\n",
    "print(\"Img3 - real: 12, pred: %d\" % (np.argmax(preds[2], axis=0)*6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
