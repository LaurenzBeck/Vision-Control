{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt: Transfer Learning with InceptionResNet and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "print(tf.keras.__version__)\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "SEED = 42\n",
    "SESSION_NAME = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "PI = tf.constant(np.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=pd.read_csv(\"./labels_all_added_shifted.csv\",dtype={'id': str, 'label_rad': np.float32, 'label_scaled': np.float32, 'label_scaled_shifted': np.float32, 'label_sin': np.float32, 'label_cos': np.float32})\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing some Examples\n",
    "IMG_PATH = \"images/\"\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "for i in range (1, 5):\n",
    "    a = fig.add_subplot(2, 2, i)\n",
    "    imgplot = plt.imshow(mpimg.imread(IMG_PATH+traindf.iloc[(i*5000)-1]['id']), cmap='gray', vmin=0, vmax=1)\n",
    "    a.set_title(traindf.iloc[(i*5000)-1]['label_rad']) \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input constants\n",
    "HEIGHT = 480\n",
    "WIDTH = 640\n",
    "TARGET_HEIGHT = 240\n",
    "TARGET_WIDTH = 320\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 8\n",
    "VAL_SPLIT = 0.01\n",
    "NUM_IMAGES = 55479\n",
    "NUM_TRAIN_IMAGES = NUM_IMAGES*(1-VAL_SPLIT)\n",
    "NUM_VAL_IMAGES = NUM_IMAGES*VAL_SPLIT\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(validation_split=VAL_SPLIT,\n",
    "                                                       rescale = 1/256,\n",
    "                                                       width_shift_range = 10,\n",
    "                                                       height_shift_range = 10,\n",
    "                                                       rotation_range = 5,\n",
    "                                                       brightness_range = [0.5, 1.5],\n",
    "                                                       zoom_range = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=traindf,\n",
    "                                                    directory=IMG_PATH,\n",
    "                                                    x_col=\"id\",\n",
    "                                                    y_col=\"label_scaled\",\n",
    "                                                    subset=\"training\",\n",
    "                                                    seed=SEED,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"other\",\n",
    "                                                    target_size=(TARGET_HEIGHT,TARGET_WIDTH),\n",
    "                                                    color_mode = \"rgb\")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=traindf,\n",
    "                                                    directory=IMG_PATH,\n",
    "                                                    x_col=\"id\",\n",
    "                                                    y_col=\"label_scaled\", #evt. None\n",
    "                                                    subset=\"validation\",\n",
    "                                                    seed=SEED,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"other\", #evt. None\n",
    "                                                    target_size=(TARGET_HEIGHT,TARGET_WIDTH),\n",
    "                                                    color_mode = \"rgb\")\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "for X_batch, y_batch in train_generator:\n",
    "    for i in range(1, 9):\n",
    "        image = ((X_batch[i-1]*256).astype('uint8'))#[:,:,0]\n",
    "        a = fig.add_subplot(4, 2, i)\n",
    "        imgplot = plt.imshow(image, cmap='gray', vmin = 0, vmax = 256)\n",
    "        a.set_title(\"{}\".format(i))\n",
    "        plt.tight_layout()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective Function\n",
    "def scaled_and_shifted_squared_angdiff(y_true, y_pred):\n",
    "    y_true_scaled = (y_true+0.5)*2*PI\n",
    "    y_pred_scaled = (y_pred+0.5)*2*PI\n",
    "    delta = tf.atan2(tf.sin(y_pred_scaled-y_true_scaled), tf.cos(y_pred_scaled-y_true_scaled))\n",
    "    loss = tf.square(delta)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the objective Function\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "feed_dict={x: [-0.49, 0], y: [0.49, 0.5]}\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(scaled_and_shifted_squared_angdiff(x, y), feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Definition\n",
    "model = Sequential()\n",
    "model.add(InceptionResNetV2(include_top=False,\n",
    "                            weights='imagenet',\n",
    "                            input_shape=(TARGET_HEIGHT,TARGET_WIDTH,3),\n",
    "                            pooling='avg'))\n",
    "model.add(Dense(128, activation=\"elu\"))\n",
    "model.add(Dropout(0.05, seed=SEED))\n",
    "model.add(Dense(64, activation=\"elu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training constants\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 0.0003\n",
    "DECAY = 1e-6\n",
    "\n",
    "FILEPATH_SAVE='checkpoints/{}_model_weights.h5'.format(SESSION_NAME)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(FILEPATH_SAVE,\n",
    "                                             monitor=[scaled_and_shifted_squared_angdiff],\n",
    "                                             verbose=1,\n",
    "                                             mode='max')\n",
    "\n",
    "#Tensorboard Callback\n",
    "FILEPATH_TENSORBOARD_LOG = 'logdir/{}'.format(SESSION_NAME)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir = FILEPATH_TENSORBOARD_LOG,\n",
    "                                          histogram_freq=1,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          write_graph=True,\n",
    "                                          write_grads=True,\n",
    "                                          write_images=True,\n",
    "                                          update_freq=NUM_TRAIN_IMAGES//5\n",
    "                                         )\n",
    "\n",
    "model.compile(optimizer='adam', #keras.optimizers.rmsprop(lr=LEARNING_RATE, decay=DECAY),\n",
    "                loss=scaled_and_shifted_squared_angdiff,\n",
    "                metrics=[scaled_and_shifted_squared_angdiff])\n",
    "\n",
    "#starting Tensorboard:\n",
    "#Navigated the browser to http://localhost:8088\n",
    "#cd to current directory\n",
    "#%tensorboard --logdir=logdir/ --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                               epochs=NUM_EPOCHS,\n",
    "                               workers=4, \n",
    "                               steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE, \n",
    "                               validation_data = val_generator,\n",
    "                               validation_steps = NUM_VAL_IMAGES // BATCH_SIZE,\n",
    "                               shuffle=True,\n",
    "                               callbacks=[tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict_generator(val_generator, verbose=1)\n",
    "filenames=val_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":pred.tolist()})\n",
    "results.to_csv(\"results_{}.csv\".format(SESSION_NAME),index=False)\n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
