{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "print(tf.keras.__version__)\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input constants\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "base_model = keras.applications.resnet50.ResNet50(weights='imagenet', \n",
    "                                                  include_top=False, \n",
    "                                                  input_shape=(HEIGHT, WIDTH, CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".png\"\n",
    "\n",
    "traindf=pd.read_csv(\"./trainLabels.csv\",dtype=str)\n",
    "testdf=pd.read_csv(\"./sampleSubmission.csv\",dtype=str)\n",
    "traindf[\"id\"]=traindf[\"id\"].apply(append_ext)\n",
    "testdf[\"id\"]=testdf[\"id\"].apply(append_ext)\n",
    "#datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "#visualizing some examples\n",
    "IMG_PATH_1 = \"train/1.PNG\"\n",
    "IMG_PATH_2 = \"train/2.PNG\"\n",
    "IMG_PATH_3 = \"train/3.PNG\"\n",
    "IMG_PATH_4 = \"train/4.PNG\"\n",
    "\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1, 4, 1)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_1), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Frog') \n",
    "a = fig.add_subplot(1, 4, 2)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_2), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Truck') \n",
    "a = fig.add_subplot(1, 4, 3)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_3), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Truck');\n",
    "a = fig.add_subplot(1, 4, 4)\n",
    "imgplot = plt.imshow(mpimg.imread(IMG_PATH_4), cmap='gray', vmin=0, vmax=1)\n",
    "a.set_title('Deer');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.25\n",
    "NUM_IMAGES = 50000\n",
    "NUM_TEST_IMAGES = 300000\n",
    "NUM_TRAIN_IMAGES = NUM_IMAGES*(1-VALIDATION_SPLIT)\n",
    "NUM_VAL_IMAGES = NUM_IMAGES*VALIDATION_SPLIT\n",
    "\n",
    "train_datagen =  keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.resnet50.preprocess_input,\n",
    "                                                              validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=traindf,\n",
    "                                                    directory=\"./train/\",\n",
    "                                                    x_col=\"id\",\n",
    "                                                    y_col=\"label\",\n",
    "                                                    subset=\"training\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    seed=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    target_size=(HEIGHT,WIDTH))\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(dataframe=traindf,\n",
    "                                                directory=\"./train/\",\n",
    "                                                x_col=\"id\",\n",
    "                                                y_col=\"label\",\n",
    "                                                subset=\"validation\",\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                seed=42,\n",
    "                                                shuffle=True,\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(HEIGHT,WIDTH))\n",
    "\n",
    "test_datagen =  keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.resnet50.preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=testdf,\n",
    "                                                    directory=\"./test/\",\n",
    "                                                    x_col=\"id\",\n",
    "                                                    y_col=None,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    seed=42,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode=None,\n",
    "                                                    target_size=(HEIGHT,WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = Dropout(dropout)(x)\n",
    "    predictions = Dense(num_classes, activation='sigmoid')(x) \n",
    "    finetune_model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return finetune_model\n",
    "\n",
    "# Top Layer constants\n",
    "FC_LAYERS = [32]\n",
    "DROPOUT = 0.05\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=DROPOUT, \n",
    "                                      fc_layers=FC_LAYERS, \n",
    "                                      num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training constants\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "DECAY = 1e-6\n",
    "\n",
    "#Callbacks\n",
    "FILEPATH_SAVE='checkpoints/ResNet50_{}_model_weights.h5'.format(time())\n",
    "FILEPATH_TENSORBOARD_LOG = 'logdir/{}'.format(int(time()))\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(FILEPATH_SAVE,\n",
    "                                             monitor=[\"acc\"],\n",
    "                                             verbose=1,\n",
    "                                             mode='max')\n",
    "                                               \n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='acc',\n",
    "                                               min_delta=0.002,\n",
    "                                               patience=4,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto',\n",
    "                                               restore_best_weights=True)\n",
    "                                               \n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir = FILEPATH_TENSORBOARD_LOG, write_images=True)\n",
    "\n",
    "callbacks_list = [tensorboard]\n",
    "\n",
    "finetune_model.compile(keras.optimizers.rmsprop(lr=LEARNING_RATE, decay=DECAY),\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "history = finetune_model.fit_generator(train_generator, \n",
    "                                       epochs=NUM_EPOCHS,\n",
    "                                       workers=8, \n",
    "                                       steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE, \n",
    "                                       validation_data = valid_generator,\n",
    "                                       validation_steps = NUM_VAL_IMAGES // BATCH_SIZE,\n",
    "                                       shuffle=True,\n",
    "                                       callbacks=callbacks_list\n",
    "                                      )\n",
    "\n",
    "#starting Tensorboard:\n",
    "#tensorboard --logdir=data/ --host localhost --port 8088\n",
    "#Navigated the browser to http://localhost:8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model.evaluate_generator(generator=valid_generator,\n",
    "steps=NUM_VAL_IMAGES // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=finetune_model.predict_generator(test_generator,\n",
    "                                        steps=NUM_TEST_IMAGES // BATCH_SIZE,\n",
    "                                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results_transfer_learning.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model.save('cifar10_trained_with_transfer_learning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
