{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\Laurenz\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Laurenz\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Laurenz\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 34s 672us/sample - loss: 1.8472 - acc: 0.3192 - val_loss: 1.5642 - val_acc: 0.4412\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 17s 342us/sample - loss: 1.5455 - acc: 0.4373 - val_loss: 1.3978 - val_acc: 0.4880\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 17s 342us/sample - loss: 1.4153 - acc: 0.4911 - val_loss: 1.2780 - val_acc: 0.5496\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 17s 340us/sample - loss: 1.3176 - acc: 0.5344 - val_loss: 1.1859 - val_acc: 0.5839\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 17s 346us/sample - loss: 1.2321 - acc: 0.5644 - val_loss: 1.1313 - val_acc: 0.5935\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 17s 345us/sample - loss: 1.1652 - acc: 0.5873 - val_loss: 1.0693 - val_acc: 0.6235\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 17s 343us/sample - loss: 1.1059 - acc: 0.6117 - val_loss: 0.9968 - val_acc: 0.6478\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 17s 343us/sample - loss: 1.0555 - acc: 0.6290 - val_loss: 0.9627 - val_acc: 0.6587\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 17s 345us/sample - loss: 1.0167 - acc: 0.6443 - val_loss: 0.9426 - val_acc: 0.6672\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 17s 347us/sample - loss: 0.9778 - acc: 0.6583 - val_loss: 0.9099 - val_acc: 0.6765\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 17s 349us/sample - loss: 0.9498 - acc: 0.6675 - val_loss: 0.8624 - val_acc: 0.7005\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 17s 347us/sample - loss: 0.9235 - acc: 0.6764 - val_loss: 0.8423 - val_acc: 0.7113\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 17s 346us/sample - loss: 0.8974 - acc: 0.6858 - val_loss: 0.8216 - val_acc: 0.7205\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 17s 345us/sample - loss: 0.8819 - acc: 0.6930 - val_loss: 0.8059 - val_acc: 0.7265\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 17s 346us/sample - loss: 0.8619 - acc: 0.6994 - val_loss: 0.7825 - val_acc: 0.7312\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 17s 343us/sample - loss: 0.8467 - acc: 0.7079 - val_loss: 0.8004 - val_acc: 0.7226\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 17s 344us/sample - loss: 0.8321 - acc: 0.7121 - val_loss: 0.7778 - val_acc: 0.7316\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 17s 343us/sample - loss: 0.8204 - acc: 0.7160 - val_loss: 0.7717 - val_acc: 0.7282\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 17s 344us/sample - loss: 0.8051 - acc: 0.7225 - val_loss: 0.7742 - val_acc: 0.7356\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 17s 347us/sample - loss: 0.7919 - acc: 0.7293 - val_loss: 0.7352 - val_acc: 0.7445\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 17s 350us/sample - loss: 0.7941 - acc: 0.7273 - val_loss: 0.7334 - val_acc: 0.7433\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 18s 351us/sample - loss: 0.7784 - acc: 0.7337 - val_loss: 0.7518 - val_acc: 0.7424\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 17s 349us/sample - loss: 0.7722 - acc: 0.7367 - val_loss: 0.7223 - val_acc: 0.7537\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 17s 349us/sample - loss: 0.7654 - acc: 0.7377 - val_loss: 0.7147 - val_acc: 0.7550\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 17s 349us/sample - loss: 0.7588 - acc: 0.7417 - val_loss: 0.7397 - val_acc: 0.7443\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 17s 350us/sample - loss: 0.7510 - acc: 0.7438 - val_loss: 0.7452 - val_acc: 0.7436\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 17s 349us/sample - loss: 0.7443 - acc: 0.7462 - val_loss: 0.6996 - val_acc: 0.7565\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 17s 349us/sample - loss: 0.7443 - acc: 0.7459 - val_loss: 0.6917 - val_acc: 0.7621\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 17s 349us/sample - loss: 0.7364 - acc: 0.7514 - val_loss: 0.6863 - val_acc: 0.7658\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 18s 351us/sample - loss: 0.7281 - acc: 0.7536 - val_loss: 0.7436 - val_acc: 0.7449\n",
      "Saved trained model at C:\\Users\\Laurenz\\Desktop\\Vision-Control\\Development\\Laurenz\\simple clock regression\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 120us/sample - loss: 0.7436 - acc: 0.7449\n",
      "Test loss: 0.7435819177627564\n",
      "Test accuracy: 0.7449\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
